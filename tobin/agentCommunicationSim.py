#%%
from tools import *
import openai
import numpy as np
import os
import time

client = openai.OpenAI(
    api_key = "your api key here"
)


# Field and topic for the first LLM to generate a question
field = "Physics"
topic = "Quantum Mechanics"

# Initialize the conversation
messages = [
    {"role": "system", "content": f"You are a knowledgeable assistant in the field of {field}."},
    {"role": "user", "content": f"Generate a challenging question about {topic} for an expert to answer."},
]

# Function to communicate with the OpenAI API and get the response
def get_response(messages):
    response = client.chat.completions.create(
        model = "gpt-3.5-turbo",
        messages = messages
    )
    return response.choices[0].message

#%%
# Generate a question from the first LLM
question_response = get_response(messages)
question = question_response.content
print(f"LLM 1 (Question): {question}")

#%%
# Embed the question generated by the first LLM
embedded_question = embed_text(question)

#%%
# Prepare the second LLM to answer as an expert
# The Second LLM will invert the embedding and answer the inverted embedded question
inverted_question = invert_embedding(embedded_question)
inverted_question = inverted_question[0]
print(inverted_question)

#%%
expert_messages = [
    {"role": "system", "content": f"You are an expert in the field of {field}."},
    {"role": "user", "content": inverted_question},
]

#%%
# Get the expert answer from the second LLM
expert_response = get_response(expert_messages)
answer = expert_response.content
print(f"LLM 2 (Expert Answer): {answer}")

#The second LLM will now embed their answer to the question
embedded_answer = embed_text([answer])

#The first LLM will now invert the embedding of the answer to the question
inverted_answer = invert_embedding(embedded_answer)
print(inverted_answer)
inverted_answer = inverted_answer[0]

# Print the full conversation
conversation = [
    {"role": "system", "content": f"First LLM generates a question about {topic} in {field}."},
    {"role": "user", "content": "Generate a challenging question about Quantum Mechanics for an expert to answer."},
    {"role": "assistant", "content": question},
    {"role": "system", "content": f"Second LLM answers as an expert in {field}."},
    {"role": "user", "content": inverted_question},
    {"role": "assistant", "content": answer},
    {"role": "system", "content": f"First LLM receives the following sentence as a response: \n{inverted_answer}"},
    {"role": "system", "content": "Conversation completed."},
]

for message in conversation:
    print(f"{message['role'].capitalize()}: {message['content']}")
# %%
